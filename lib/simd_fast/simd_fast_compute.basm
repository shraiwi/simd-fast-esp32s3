    .section .rodata
._lit_shift_mask:
    .align 16
    .byte 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
._lit_const_h10:
    .align 16
    .byte 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10
._lit_const_ones:
    .align 16
    .byte 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1

    .section .literal
._lit_magic:
    .word 0x01010101

    .section .text
    .literal ._lit_shift_mask_addr, ._lit_shift_mask
    .literal ._lit_const_h10_addr, ._lit_const_h10
    .literal ._lit_const_ones_addr, ._lit_const_ones

    .global simd_fast_compute
    .type   simd_fast_compute,@function
# compute the score and whether or not a pixel satisfies the FAST detector criteria
# uint32_t simd_fast_compute(uint32_t center, const simdu8x16 pixels, uint32_t b)
simd_fast_compute:
    entry           a1, 16            # prepare windowed registers and reserve 16 bytes of stack

    #define center a2
    #define pixels a3
    #define b a4
    // #define out a5

    # splat b across b_128
    #define b_32 a15
    l32r            b_32, ._lit_magic   # b_32 = 0x01010101
    mull            b_32, b_32, b       # b_32 *= b

    #define b_128 q0
    ee.movi.32.q    b_128, b_32, 0      # b_128[0:4] = b ; 1 byte is b
    ee.movi.32.q    b_128, b_32, 1
    ee.movi.32.q    b_128, b_32, 2
    ee.movi.32.q    b_128, b_32, 3
    #undef b_32

    # splat center across center_128
    #define center_32 a15
    l32r            center_32, ._lit_magic          # center_32 = 0x01010101
    mull            center_32, center_32, center    # center_32 *= center

    #define center_128 q1
    ee.movi.32.q    center_128, center_32, 0
    ee.movi.32.q    center_128, center_32, 1
    ee.movi.32.q    center_128, center_32, 2
    ee.movi.32.q    center_128, center_32, 3

    #undef center_32

    #define pix_ring q2
    #define cmp_l q3
    #define thresh q4

    ld.qr           pix_ring, pixels, 0                 # pix_ring = pixels[0:16]
    ee.zero.q       cmp_l                               # cmp_l = [0, ] * 16

    ee.vadds.s8     thresh, center_128, b_128           # thresh = pix_ring + b
    ee.vcmp.gt.s8   thresh, pix_ring, thresh            # thresh = -1 where pix_ring > thresh else 0
    ee.vsubs.s8     cmp_l, cmp_l, thresh                # cmp_l -= thresh

    #define const_h10_addr a15
    l32r            const_h10_addr, ._lit_const_h10_addr    # const_h10_addr = &.const_h10[0]
    #define const_h10 q5
    ld.qr           const_h10, const_h10_addr, 0        # const_h10 = const_h10_addr[0:16]
    #undef const_h10_addr

    ee.vsubs.s8     thresh, center_128, b_128           # thresh = pix_ring - b
    ee.vcmp.lt.s8   thresh, pix_ring, thresh            # thresh = 0xff where pix_ring < thresh else 0x00
    ee.andq         thresh, const_h10, thresh           # thresh &= [0x10, ] * 16
    ee.orq          cmp_l, cmp_l, thresh                # cmp_l |= thresh

    # cmp_l contains 0x10 for low extrema and/or 0x01 for high extrema.

    #undef const_h10
    #undef thresh

    #define cmp_h q4

    #define shift_mask_addr a15
    l32r            shift_mask_addr, ._lit_shift_mask_addr
    #define shift_mask q5
    ld.qr           shift_mask, shift_mask_addr, 0
    #undef shift_mask_addr

    #define const_zero a15
    #define const_hc0 a14
    #define const_hc a13
    #define loopcount a12
    #define lomask a11
    #define contiguous a10
    #define contiguous_lo a9

    movi.n          const_zero, 0
    movi            const_hc0, 0xc0
    movi.n          const_hc, 0xc
    movi.n          loopcount, 16
    movi.n          lomask, 0xf
    movi.n          a2, 1

    loopnez loopcount, simd_fast_compute_nomatch

    # todo: find a better way to clear ACCX
    wur.accx_0          const_zero                  # ACCX[0:4] = 0
    wur.accx_1          const_zero                  # ACCX[4:5] = 0
    ee.vmulas.u8.accx   cmp_l, shift_mask           # ACCX = dot(cmp_l, shift_mask)
    ee.srs.accx         contiguous, const_zero, 0   # contiguous = ACCX >> 0

    bgeu        contiguous, const_hc0, simd_fast_compute_match      # if high
    and         contiguous_lo, contiguous, lomask                   # contiguous_lo &= 0xf
    bgeu        contiguous_lo, const_hc, simd_fast_compute_match    # if contiguous lo has 12 or more 

    # rotate 1 byte right
    ee.zero.q       cmp_h
    ee.srci.2q      cmp_l, cmp_h, 0
    ee.orq          cmp_l, cmp_l, cmp_h

    #undef contiguous_lo
    #undef contiguous
    #undef lomask
    #undef loopcount
    #undef const_hc
    #undef const_hc0
    # #undef const_zero // i still need u

    #undef shift_mask
    #undef cmp_h
    #undef cmp_l

simd_fast_compute_nomatch: 
    movi.n          a2, -1                      # retval = 0
    j               simd_fast_compute_return    # return
simd_fast_compute_match:
    #define const_ones_addr a14
    l32r            const_ones_addr, ._lit_const_ones_addr
    #define const_ones q3
    ld.qr           const_ones, const_ones_addr, 0
    #undef const_ones_addr

    #define const_neg1 a14
    movi                const_neg1, -1

    ee.vsubs.s8         pix_ring, pix_ring, center_128      # pix_ring -= center_128
    ee.vrelu.s8         pix_ring, const_neg1, const_zero    # pix_ring = (pix_ring * -1) >> 0 where pix_ring <= 0 else pix_ring ; abs

    wur.accx_0          const_zero                      # ACCX[0:4] = 0
    wur.accx_1          const_zero                      # ACCX[4:5] = 0
    ee.vmulas.u8.accx   pix_ring, const_ones            # ACCX += dot(pix_ring, [1, ] * 16)
    ee.srs.accx         a2, const_zero, 0               # retval = ACCX >> 0

    #undef const_neg1
    #undef const_zero
simd_fast_compute_return:
    # st.qr           pix_ring, out, 0
    retw                        # restore state (windowed registers) and return to caller